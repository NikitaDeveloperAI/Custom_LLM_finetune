{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5984dc8-e625-4b2e-9791-95e8d7fb48ed",
   "metadata": {},
   "source": [
    "## Using LLMs for synthetic data generation\n",
    "\n",
    "This notebook explores ways to synthetically generate data for training / finetuning other LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7576a73-beb0-4459-8ed8-5fe0dd87ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import langchain\n",
    "from langchain.llms import Ollama\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain_community.chat_models import GigaChat\n",
    "from langchain_experimental.tabular_synthetic_data.base import SyntheticDataGenerator\n",
    "from langchain_experimental.tabular_synthetic_data.openai import create_openai_data_generator, OPENAI_TEMPLATE\n",
    "from langchain_experimental.tabular_synthetic_data.prompts import SYNTHETIC_FEW_SHOT_SUFFIX, SYNTHETIC_FEW_SHOT_PREFIX\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from api_keys import (HUGGINGFACEHUB_API_TOKEN, \n",
    "                      OPENAI_API_KEY, \n",
    "                      client_secret_sber, \n",
    "                      credentials_sber,\n",
    "                      )\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c79e1-bffd-42f0-8360-6ee568f430d2",
   "metadata": {},
   "source": [
    "## Option 1\n",
    "\n",
    "In this specific case, GPT-3.5-turbo is used to generate SQL code. Note that due to the use of GPT-3.5-turbo, the code must either be run on Google Colab, or with a VPN that identifies the user's queries as originating in some other country than Russia. Otherwise, `ChatOpenAI()` will yield an error due to requests with Russian IP addresses being blocked by OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b071c-2093-4d6c-b1a7-9c73ab66ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama_parameters = {\n",
    "#     \"model\": \"codellama\",\n",
    "#     \"top_p\": 0.95,\n",
    "#     \"temperature\": 0.0,\n",
    "#     \"repeat_penalty\": 1.1,\n",
    "#     \"num_gpu\": None,\n",
    "#     \"timeout\": None,\n",
    "#     \"num_ctx\": 4096,\n",
    "# }\n",
    "# llm_model = Ollama(**llama_parameters)\n",
    "\n",
    "llm_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af7d9e1-6655-4629-bd71-2841b555b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# message = \"\"\"[INST] <<SYS>>You are an SQL code generator. Do not write anything except an SQL query.<</SYS>>\n",
    "\n",
    "# Please generate one random SQL query for me.[/INST]\"\"\"\n",
    "\n",
    "# llm_model.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c2c68-c3ea-49f2-8628-060e9271f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLCode(BaseModel):\n",
    "    query: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\"example\": \n",
    "     \"\"\"query: I need to select all users from database 'employees' whose 'work_category' is 'HR', and who have an annual salary higher than $50,000.,\n",
    "     answer: SELECT * FROM employees WHERE work_category == 'HR'\"\"\"},\n",
    "    {\"example\": \n",
    "     \"\"\"query: How do I select all items from database 'menu' which are priced between $5 and $15?,\n",
    "     answer: SELECT * FROM menu WHERE price >= 5 and price <= 15\"\"\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339eec2-3e52-4d78-bf32-44865c267c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_TEMPLATE = PromptTemplate(input_variables=[\"example\"], template=\"{example}\")\n",
    "\n",
    "prompt_template = FewShotPromptTemplate(\n",
    "    prefix=SYNTHETIC_FEW_SHOT_PREFIX,\n",
    "    examples=examples,\n",
    "    suffix=SYNTHETIC_FEW_SHOT_SUFFIX,\n",
    "    input_variables=[\"subject\", \"extra\"],\n",
    "    example_prompt=OPENAI_TEMPLATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e93aa7-0572-4dd6-9c1c-f1265d217361",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_generator = create_openai_data_generator(\n",
    "    output_schema=SQLCode, \n",
    "    llm=llm_model, \n",
    "    prompt=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde35128-8130-4b28-83a4-f8c81e384ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_results = synthetic_data_generator.generate(\n",
    "    subject=\"SQL_CODE\",\n",
    "    extra=\"Each query must be unique. Make up something interesting.\",\n",
    "    runs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004a11e8-a6b5-4847-96fd-d5c77b94e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafd8bd-03f6-4c34-90d0-c2e73b3db47e",
   "metadata": {},
   "source": [
    "## Option 2\n",
    "\n",
    "work in progress..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
